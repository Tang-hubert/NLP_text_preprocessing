{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\luke1\\Downloads\\textmining\\Amazon book reviews\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books_rating.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pandas.read_csv(f\"{path}\\Books_rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Id                           Title  Price         User_id  \\\n",
      "0        1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
      "1        0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
      "2        0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
      "3        0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
      "4        0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
      "...             ...                             ...    ...             ...   \n",
      "2999995  B000NSLVCU             The Idea of History    NaN             NaN   \n",
      "2999996  B000NSLVCU             The Idea of History    NaN  A1SMUB9ASL5L9Y   \n",
      "2999997  B000NSLVCU             The Idea of History    NaN  A2AQMEKZKK5EE4   \n",
      "2999998  B000NSLVCU             The Idea of History    NaN  A18SQGYBKS852K   \n",
      "2999999  B000NSLVCU             The Idea of History    NaN             NaN   \n",
      "\n",
      "                                profileName review/helpfulness  review/score  \\\n",
      "0                     Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
      "1                             Kevin Killian              10/10           5.0   \n",
      "2                              John Granger              10/11           5.0   \n",
      "3        Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
      "4           D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
      "...                                     ...                ...           ...   \n",
      "2999995                                 NaN              14/19           4.0   \n",
      "2999996                             jafrank                1/1           4.0   \n",
      "2999997           L. L. Poulos \"Muslim Mom\"                0/0           4.0   \n",
      "2999998       Julia A. Klein \"knitting rat\"               1/11           5.0   \n",
      "2999999                                 NaN               7/49           1.0   \n",
      "\n",
      "         review/time                                     review/summary  \\\n",
      "0          940636800             Nice collection of Julie Strain images   \n",
      "1         1095724800                                  Really Enjoyed It   \n",
      "2         1078790400    Essential for every personal and Public Library   \n",
      "3         1090713600    Phlip Nel gives silly Seuss a serious treatment   \n",
      "4         1107993600                             Good academic overview   \n",
      "...              ...                                                ...   \n",
      "2999995    937612800                                          Difficult   \n",
      "2999996   1331683200      Quite good and ahead of its time occasionally   \n",
      "2999997   1180224000  Easier reads of those not well versed in histo...   \n",
      "2999998   1163030400   Yes, it is cheaper than the University Bookstore   \n",
      "2999999    905385600  Collingwood's ideas sink in a quagmire or verb...   \n",
      "\n",
      "                                               review/text  \n",
      "0        This is only for Julie Strain fans. It's a col...  \n",
      "1        I don't care much for Dr. Seuss but after read...  \n",
      "2        If people become the books they read and if \"t...  \n",
      "3        Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
      "4        Philip Nel - Dr. Seuss: American IconThis is b...  \n",
      "...                                                    ...  \n",
      "2999995  This is an extremely difficult book to digest,...  \n",
      "2999996  This is pretty interesting. Collingwood seems ...  \n",
      "2999997  This is a good book but very esoteric. \"What i...  \n",
      "2999998  My daughter, a freshman at Indiana University,...  \n",
      "2999999  The guy has a few good ideas but, reader, bewa...  \n",
      "\n",
      "[3000000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "Title\n",
      "Price\n",
      "User_id\n",
      "profileName\n",
      "review/helpfulness\n",
      "review/score\n",
      "review/time\n",
      "review/summary\n",
      "review/text\n"
     ]
    }
   ],
   "source": [
    "for col in df_rating.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_review_text = df_rating['review/text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(df_rating_review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'only', 'for', 'Julie', 'Strain', 'fans', '.'], ['It', \"'s\", 'a', 'collection', 'of', 'her', 'photos', '--', 'about', '80', 'pages', 'worth', 'with', 'a', 'nice', 'section', 'of', 'paintings', 'by', 'Olivia.If', 'you', \"'re\", 'looking', 'for', 'heavy', 'literary', 'content', ',', 'this', 'is', \"n't\", 'the', 'place', 'to', 'find', 'it', '--', 'there', \"'s\", 'only', 'about', '2', 'pages', 'with', 'text', 'and', 'everything', 'else', 'is', 'photos.Bottom', 'line', ':', 'if', 'you', 'only', 'want', 'one', 'book', ',', 'the', 'Six', 'Foot', 'One', '...', 'is', 'probably', 'a', 'better', 'choice', ',', 'however', ',', 'if', 'you', 'like', 'Julie', 'like', 'I', 'like', 'Julie', ',', 'you', 'wo', \"n't\", 'go', 'wrong', 'on', 'this', 'one', 'either', '.']]\n"
     ]
    }
   ],
   "source": [
    "tokens = [nltk.tokenize.word_tokenize(sent) for sent in sentences]\n",
    "print(tokens)\n",
    "# for token in tokens:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('only', 'RB'), ('for', 'IN'), ('Julie', 'NNP'), ('Strain', 'NNP'), ('fans', 'NNS'), ('.', '.')]\n",
      "[('It', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('photos', 'NNS'), ('--', ':'), ('about', 'IN'), ('80', 'CD'), ('pages', 'NNS'), ('worth', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('nice', 'JJ'), ('section', 'NN'), ('of', 'IN'), ('paintings', 'NNS'), ('by', 'IN'), ('Olivia.If', 'NNP'), ('you', 'PRP'), (\"'re\", 'VBP'), ('looking', 'VBG'), ('for', 'IN'), ('heavy', 'JJ'), ('literary', 'JJ'), ('content', 'NN'), (',', ','), ('this', 'DT'), ('is', 'VBZ'), (\"n't\", 'RB'), ('the', 'DT'), ('place', 'NN'), ('to', 'TO'), ('find', 'VB'), ('it', 'PRP'), ('--', ':'), ('there', 'EX'), (\"'s\", 'VBZ'), ('only', 'RB'), ('about', 'RB'), ('2', 'CD'), ('pages', 'NNS'), ('with', 'IN'), ('text', 'NN'), ('and', 'CC'), ('everything', 'NN'), ('else', 'RB'), ('is', 'VBZ'), ('photos.Bottom', 'JJ'), ('line', 'NN'), (':', ':'), ('if', 'IN'), ('you', 'PRP'), ('only', 'RB'), ('want', 'VBP'), ('one', 'CD'), ('book', 'NN'), (',', ','), ('the', 'DT'), ('Six', 'NNP'), ('Foot', 'NNP'), ('One', 'CD'), ('...', ':'), ('is', 'VBZ'), ('probably', 'RB'), ('a', 'DT'), ('better', 'JJR'), ('choice', 'NN'), (',', ','), ('however', 'RB'), (',', ','), ('if', 'IN'), ('you', 'PRP'), ('like', 'VBP'), ('Julie', 'NNP'), ('like', 'IN'), ('I', 'PRP'), ('like', 'VBP'), ('Julie', 'NNP'), (',', ','), ('you', 'PRP'), ('wo', 'MD'), (\"n't\", 'RB'), ('go', 'VB'), ('wrong', 'JJ'), ('on', 'IN'), ('this', 'DT'), ('one', 'CD'), ('either', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos = [nltk.pos_tag(token) for token in tokens]\n",
    "for item in pos:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "be\n",
      "only\n",
      "for\n",
      "Julie\n",
      "Strain\n",
      "fan\n",
      ".\n",
      "It\n",
      "'s\n",
      "a\n",
      "collection\n",
      "of\n",
      "her\n",
      "photo\n",
      "--\n",
      "about\n",
      "80\n",
      "page\n",
      "worth\n",
      "with\n",
      "a\n",
      "nice\n",
      "section\n",
      "of\n",
      "painting\n",
      "by\n",
      "Olivia.If\n",
      "you\n",
      "'re\n",
      "looking\n",
      "for\n",
      "heavy\n",
      "literary\n",
      "content\n",
      ",\n",
      "this\n",
      "be\n",
      "n't\n",
      "the\n",
      "place\n",
      "to\n",
      "find\n",
      "it\n",
      "--\n",
      "there\n",
      "'s\n",
      "only\n",
      "about\n",
      "2\n",
      "page\n",
      "with\n",
      "text\n",
      "and\n",
      "everything\n",
      "else\n",
      "is\n",
      "photos.Bottom\n",
      "line\n",
      ":\n",
      "if\n",
      "you\n",
      "only\n",
      "want\n",
      "one\n",
      "book\n",
      ",\n",
      "the\n",
      "Six\n",
      "Foot\n",
      "One\n",
      "...\n",
      "is\n",
      "probably\n",
      "a\n",
      "better\n",
      "choice\n",
      ",\n",
      "however\n",
      ",\n",
      "if\n",
      "you\n",
      "like\n",
      "Julie\n",
      "like\n",
      "I\n",
      "like\n",
      "Julie\n",
      ",\n",
      "you\n",
      "wo\n",
      "n't\n",
      "go\n",
      "wrong\n",
      "on\n",
      "this\n",
      "one\n",
      "either\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "wordnet_pos = []\n",
    "for p in pos:\n",
    "    for word, tag in p:\n",
    "        if tag.startswith('J'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.ADJ)\n",
    "        elif tag.startswith('V'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.VERB)\n",
    "        elif tag.startswith('N'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n",
    "        elif tag.startswith('R'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.ADV)\n",
    "        else:\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "# Lemmatizer\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(p[n][0], pos=wordnet_pos[n]) for p in pos for n in range(len(p))]\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "Julie\n",
      "Strain\n",
      "fan\n",
      ".\n",
      "It\n",
      "'s\n",
      "collection\n",
      "photo\n",
      "--\n",
      "80\n",
      "page\n",
      "worth\n",
      "nice\n",
      "section\n",
      "painting\n",
      "Olivia.If\n",
      "'re\n",
      "looking\n",
      "heavy\n",
      "literary\n",
      "content\n",
      ",\n",
      "n't\n",
      "place\n",
      "find\n",
      "--\n",
      "'s\n",
      "2\n",
      "page\n",
      "text\n",
      "everything\n",
      "else\n",
      "photos.Bottom\n",
      "line\n",
      ":\n",
      "want\n",
      "one\n",
      "book\n",
      ",\n",
      "Six\n",
      "Foot\n",
      "One\n",
      "...\n",
      "probably\n",
      "better\n",
      "choice\n",
      ",\n",
      "however\n",
      ",\n",
      "like\n",
      "Julie\n",
      "like\n",
      "I\n",
      "like\n",
      "Julie\n",
      ",\n",
      "wo\n",
      "n't\n",
      "go\n",
      "wrong\n",
      "one\n",
      "either\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "tokens = [token for token in tokens if token not in nltk_stopwords]\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Six', 'ORGANIZATION')\n",
      "('Julie Strain', 'PERSON')\n",
      "('Julie', 'PERSON')\n"
     ]
    }
   ],
   "source": [
    "ne_chunked_sents = [nltk.ne_chunk(tag) for tag in pos]\n",
    "named_entities = []\n",
    "\n",
    "for ne_tagged_sentence in ne_chunked_sents:\n",
    "    for tagged_tree in ne_tagged_sentence:\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tagged_tree.leaves())\n",
    "            entity_type = tagged_tree.label()\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "            named_entities = list(set(named_entities))\n",
    "\n",
    "for ner in named_entities:\n",
    "    print(ner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Title  \\\n",
      "0                          Its Only Art If Its Well Hung!   \n",
      "1                                Dr. Seuss: American Icon   \n",
      "2                   Wonderful Worship in Smaller Churches   \n",
      "3                           Whispers of the Wicked Saints   \n",
      "4       Nation Dance: Religion, Identity and Cultural ...   \n",
      "...                                                   ...   \n",
      "212399  The Orphan Of Ellis Island (Time Travel Advent...   \n",
      "212400                            Red Boots for Christmas   \n",
      "212401                                              Mamaw   \n",
      "212402                                  The Autograph Man   \n",
      "212403  Student's Solutions Manual for Johnson/Mowry's...   \n",
      "\n",
      "                                              description  \\\n",
      "0                                                     NaN   \n",
      "1       Philip Nel takes a fascinating look into the k...   \n",
      "2       This resource includes twelve principles in un...   \n",
      "3       Julia Thomas finds her life spinning out of co...   \n",
      "4                                                     NaN   \n",
      "...                                                   ...   \n",
      "212399  During a school trip to Ellis Island, Dominick...   \n",
      "212400  Everyone in the village of Friedensdorf is hap...   \n",
      "212401  Give your Mamaw a useful, beautiful and though...   \n",
      "212402  Alex-Li Tandem sells autographs. His business ...   \n",
      "212403  Discover the many ways mathematics is relevant...   \n",
      "\n",
      "                                        authors  \\\n",
      "0                              ['Julie Strain']   \n",
      "1                                ['Philip Nel']   \n",
      "2                              ['David R. Ray']   \n",
      "3                           ['Veronica Haddon']   \n",
      "4                               ['Edward Long']   \n",
      "...                                         ...   \n",
      "212399                      ['Elvira Woodruff']   \n",
      "212400                                      NaN   \n",
      "212401                    ['Wild Wild Cabbage']   \n",
      "212402                          ['Zadie Smith']   \n",
      "212403  ['David B. Johnson', 'Thomas A. Mowry']   \n",
      "\n",
      "                                                    image  \\\n",
      "0       http://books.google.com/books/content?id=DykPA...   \n",
      "1       http://books.google.com/books/content?id=IjvHQ...   \n",
      "2       http://books.google.com/books/content?id=2tsDA...   \n",
      "3       http://books.google.com/books/content?id=aRSIg...   \n",
      "4                                                     NaN   \n",
      "...                                                   ...   \n",
      "212399  http://books.google.com/books/content?id=J7M-N...   \n",
      "212400  http://books.google.com/books/content?id=3n8k6...   \n",
      "212401                                                NaN   \n",
      "212402  http://books.google.com/books/content?id=JM6YV...   \n",
      "212403  http://books.google.com/books/content?id=dehfP...   \n",
      "\n",
      "                                              previewLink  \\\n",
      "0       http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
      "1       http://books.google.nl/books?id=IjvHQsCn_pgC&p...   \n",
      "2       http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
      "3       http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
      "4       http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
      "...                                                   ...   \n",
      "212399  http://books.google.com/books?id=J7M-NwAACAAJ&...   \n",
      "212400  http://books.google.com/books?id=3n8k6wl4BbYC&...   \n",
      "212401  http://books.google.com/books?id=zytVswEACAAJ&...   \n",
      "212402  http://books.google.com/books?id=JM6YVPx_clMC&...   \n",
      "212403  http://books.google.com/books?id=dehfPgAACAAJ&...   \n",
      "\n",
      "                             publisher publishedDate  \\\n",
      "0                                  NaN          1996   \n",
      "1                            A&C Black    2005-01-01   \n",
      "2                                  NaN          2000   \n",
      "3                            iUniverse       2005-02   \n",
      "4                                  NaN    2003-03-01   \n",
      "...                                ...           ...   \n",
      "212399           Scholastic Paperbacks    2000-06-01   \n",
      "212400                             NaN          1995   \n",
      "212401                             NaN    2018-01-17   \n",
      "212402                         Vintage    2003-08-12   \n",
      "212403  Brooks/Cole Publishing Company    1998-01-01   \n",
      "\n",
      "                                                 infoLink  \\\n",
      "0       http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
      "1       http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
      "2       http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
      "3       http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
      "4       http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
      "...                                                   ...   \n",
      "212399  http://books.google.com/books?id=J7M-NwAACAAJ&...   \n",
      "212400  http://books.google.com/books?id=3n8k6wl4BbYC&...   \n",
      "212401  http://books.google.com/books?id=zytVswEACAAJ&...   \n",
      "212402  https://play.google.com/store/books/details?id...   \n",
      "212403  http://books.google.com/books?id=dehfPgAACAAJ&...   \n",
      "\n",
      "                           categories  ratingsCount  \n",
      "0         ['Comics & Graphic Novels']           NaN  \n",
      "1       ['Biography & Autobiography']           NaN  \n",
      "2                        ['Religion']           NaN  \n",
      "3                         ['Fiction']           NaN  \n",
      "4                                 NaN           NaN  \n",
      "...                               ...           ...  \n",
      "212399           ['Juvenile Fiction']           2.0  \n",
      "212400           ['Juvenile Fiction']           NaN  \n",
      "212401                            NaN           NaN  \n",
      "212402                    ['Fiction']          19.0  \n",
      "212403                            NaN           NaN  \n",
      "\n",
      "[212404 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_data = pandas.read_csv(f\"{path}\\Books_data.csv\")\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "description\n",
      "authors\n",
      "image\n",
      "previewLink\n",
      "publisher\n",
      "publishedDate\n",
      "infoLink\n",
      "categories\n",
      "ratingsCount\n"
     ]
    }
   ],
   "source": [
    "for col in df_data.columns:\n",
    "    print(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
