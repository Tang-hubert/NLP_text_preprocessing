{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\luke1\\Downloads\\textmining\\Amazon book reviews\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books_rating.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pandas.read_csv(f\"{path}\\Books_rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Id                                              Title  Price   \n",
      "10       0829814000              Wonderful Worship in Smaller Churches  19.40  \\\n",
      "11       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
      "12       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
      "13       0829814000              Wonderful Worship in Smaller Churches  19.40   \n",
      "14       0595344550                      Whispers of the Wicked Saints  10.95   \n",
      "...             ...                                                ...    ...   \n",
      "2999953  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
      "2999954  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
      "2999955  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
      "2999956  0786182431                   Very Bad Deaths: Library Edition  90.00   \n",
      "2999988  0255364520  An End to Welfare Rights: The Rediscovery of I...  18.95   \n",
      "\n",
      "                User_id                              profileName   \n",
      "10        AZ0IOBU20TBOP                       Rev. Pamela Tinnin  \\\n",
      "11       A373VVEU6Z9M0N                     Dr. Terry W. Dorsett   \n",
      "12        AGKGOH65VTRR4          Cynthia L. Lajoy \"Cindy La Joy\"   \n",
      "13        A3OQWLU31BU1Y                            Maxwell Grant   \n",
      "14       A3Q12RK71N74LB                              Book Reader   \n",
      "...                 ...                                      ...   \n",
      "2999953  A1EC8SNPR56CLU                               Denis Dube   \n",
      "2999954  A33VKWCAV9QQKC           Paige E. Steadman \"RuneEnigma\"   \n",
      "2999955  A2PK3NTC9RMEF4                                S. Potter   \n",
      "2999956  A2D0PY6HIGTYIT  Adrian in Phoenix \"No Time for Fantasy\"   \n",
      "2999988  A25JH6CO4DVINS                                 Junglies   \n",
      "\n",
      "        review/helpfulness  review/score  review/time   \n",
      "10                    8/10           5.0    991440000  \\\n",
      "11                     1/1           5.0   1291766400   \n",
      "12                     1/1           5.0   1248307200   \n",
      "13                     1/1           5.0   1222560000   \n",
      "14                    7/11           1.0   1117065600   \n",
      "...                    ...           ...          ...   \n",
      "2999953                0/0           4.0   1285804800   \n",
      "2999954                0/0           5.0   1230249600   \n",
      "2999955                0/0           3.0   1179705600   \n",
      "2999956                5/8           5.0   1111276800   \n",
      "2999988                0/0           4.0   1045526400   \n",
      "\n",
      "                                           review/summary   \n",
      "10          Outstanding Resource for Small Church Pastors  \\\n",
      "11              Small Churches CAN Have Wonderful Worship   \n",
      "12                                  Not Just for Pastors!   \n",
      "13       Small church pastor? This is the book on worship   \n",
      "14                                               not good   \n",
      "...                                                   ...   \n",
      "2999953                         It's the way he writes it   \n",
      "2999954                           Bad Deaths, Great Book!   \n",
      "2999955                                    Still read it.   \n",
      "2999956                        Not another Callahan story   \n",
      "2999988           Heaven helps those who help themselves.   \n",
      "\n",
      "                                               review/text  \n",
      "10       I just finished the book, &quot;Wonderful Wors...  \n",
      "11       Many small churches feel like they can not hav...  \n",
      "12       I just finished reading this amazing book and ...  \n",
      "13       I hadn't been a small church pastor very long ...  \n",
      "14       I bought this book because I read some glowing...  \n",
      "...                                                    ...  \n",
      "2999953  \"Very Bad Death\" is a so so story, but the cha...  \n",
      "2999954  Very Bad Deaths was a very great book! Spider ...  \n",
      "2999955  Anything by Spider Robinson is worth reading. ...  \n",
      "2999956  Great novel! Easy & enjoyable to read straight...  \n",
      "2999988  Another book on welfare reform. Dr. Green invo...  \n",
      "\n",
      "[481171 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target data for dataframe\n",
    "df_rating = (df_rating[df_rating['Price']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_rating.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = df_rating.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "Title\n",
      "Price\n",
      "User_id\n",
      "profileName\n",
      "review/helpfulness\n",
      "review/score\n",
      "review/time\n",
      "review/summary\n",
      "review/text\n"
     ]
    }
   ],
   "source": [
    "for col in df_rating.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_review_text = df_rating['review/text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just finished the book, &quot;Wonderful Worship in Smaller Churches,&quot; by David Ray, an outstanding resource for small church pastors, as is his other book, &quot;The Big Small Church Book.&quot; I will be rereading both regularly and referring to them often. I may have to reorder the &quot;Big Small Church Book&quot; as my copy is nearly worn out. If I had only two choices for resources for pastors of small churches, it would be these two.I hope the author considers focusing on Christian Education in another book. There is a section in the &quot;Big Small Church Book&quot; on Christian Education, but concentrating on one of the most important church functions individually makes a huge difference, as is proven by this new book. I tell all my colleagues that Rev. Ray's books are worth every dollar and more.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_review_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation (斷句)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(df_rating_review_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Segmentation (斷詞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'just', 'finished', 'the', 'book', ',', '&', 'quot', ';', 'Wonderful', 'Worship', 'in', 'Smaller', 'Churches', ',', '&', 'quot', ';', 'by', 'David', 'Ray', ',', 'an', 'outstanding', 'resource', 'for', 'small', 'church', 'pastors', ',', 'as', 'is', 'his', 'other', 'book', ',', '&', 'quot', ';', 'The', 'Big', 'Small', 'Church', 'Book.', '&', 'quot', ';', 'I', 'will', 'be', 'rereading', 'both', 'regularly', 'and', 'referring', 'to', 'them', 'often', '.'], ['I', 'may', 'have', 'to', 'reorder', 'the', '&', 'quot', ';', 'Big', 'Small', 'Church', 'Book', '&', 'quot', ';', 'as', 'my', 'copy', 'is', 'nearly', 'worn', 'out', '.'], ['If', 'I', 'had', 'only', 'two', 'choices', 'for', 'resources', 'for', 'pastors', 'of', 'small', 'churches', ',', 'it', 'would', 'be', 'these', 'two.I', 'hope', 'the', 'author', 'considers', 'focusing', 'on', 'Christian', 'Education', 'in', 'another', 'book', '.'], ['There', 'is', 'a', 'section', 'in', 'the', '&', 'quot', ';', 'Big', 'Small', 'Church', 'Book', '&', 'quot', ';', 'on', 'Christian', 'Education', ',', 'but', 'concentrating', 'on', 'one', 'of', 'the', 'most', 'important', 'church', 'functions', 'individually', 'makes', 'a', 'huge', 'difference', ',', 'as', 'is', 'proven', 'by', 'this', 'new', 'book', '.'], ['I', 'tell', 'all', 'my', 'colleagues', 'that', 'Rev', '.'], ['Ray', \"'s\", 'books', 'are', 'worth', 'every', 'dollar', 'and', 'more', '.']]\n",
      "['I', 'just', 'finished', 'the', 'book', ',', '&', 'quot', ';', 'Wonderful', 'Worship', 'in', 'Smaller', 'Churches', ',', '&', 'quot', ';', 'by', 'David', 'Ray', ',', 'an', 'outstanding', 'resource', 'for', 'small', 'church', 'pastors', ',', 'as', 'is', 'his', 'other', 'book', ',', '&', 'quot', ';', 'The', 'Big', 'Small', 'Church', 'Book.', '&', 'quot', ';', 'I', 'will', 'be', 'rereading', 'both', 'regularly', 'and', 'referring', 'to', 'them', 'often', '.']\n",
      "['I', 'may', 'have', 'to', 'reorder', 'the', '&', 'quot', ';', 'Big', 'Small', 'Church', 'Book', '&', 'quot', ';', 'as', 'my', 'copy', 'is', 'nearly', 'worn', 'out', '.']\n",
      "['If', 'I', 'had', 'only', 'two', 'choices', 'for', 'resources', 'for', 'pastors', 'of', 'small', 'churches', ',', 'it', 'would', 'be', 'these', 'two.I', 'hope', 'the', 'author', 'considers', 'focusing', 'on', 'Christian', 'Education', 'in', 'another', 'book', '.']\n",
      "['There', 'is', 'a', 'section', 'in', 'the', '&', 'quot', ';', 'Big', 'Small', 'Church', 'Book', '&', 'quot', ';', 'on', 'Christian', 'Education', ',', 'but', 'concentrating', 'on', 'one', 'of', 'the', 'most', 'important', 'church', 'functions', 'individually', 'makes', 'a', 'huge', 'difference', ',', 'as', 'is', 'proven', 'by', 'this', 'new', 'book', '.']\n",
      "['I', 'tell', 'all', 'my', 'colleagues', 'that', 'Rev', '.']\n",
      "['Ray', \"'s\", 'books', 'are', 'worth', 'every', 'dollar', 'and', 'more', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = [nltk.tokenize.word_tokenize(sent) for sent in sentences]\n",
    "print(tokens)\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS (詞性標記)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('just', 'RB'), ('finished', 'VBD'), ('the', 'DT'), ('book', 'NN'), (',', ','), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('Wonderful', 'NNP'), ('Worship', 'NNP'), ('in', 'IN'), ('Smaller', 'NNP'), ('Churches', 'NNP'), (',', ','), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('by', 'IN'), ('David', 'NNP'), ('Ray', 'NNP'), (',', ','), ('an', 'DT'), ('outstanding', 'JJ'), ('resource', 'NN'), ('for', 'IN'), ('small', 'JJ'), ('church', 'NN'), ('pastors', 'NNS'), (',', ','), ('as', 'IN'), ('is', 'VBZ'), ('his', 'PRP$'), ('other', 'JJ'), ('book', 'NN'), (',', ','), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('The', 'DT'), ('Big', 'NNP'), ('Small', 'NNP'), ('Church', 'NNP'), ('Book.', 'NNP'), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('I', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('rereading', 'VBG'), ('both', 'DT'), ('regularly', 'RB'), ('and', 'CC'), ('referring', 'VBG'), ('to', 'TO'), ('them', 'PRP'), ('often', 'RB'), ('.', '.')]\n",
      "[('I', 'PRP'), ('may', 'MD'), ('have', 'VB'), ('to', 'TO'), ('reorder', 'VB'), ('the', 'DT'), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('Big', 'NNP'), ('Small', 'NNP'), ('Church', 'NNP'), ('Book', 'NNP'), ('&', 'CC'), ('quot', 'RB'), (';', ':'), ('as', 'IN'), ('my', 'PRP$'), ('copy', 'NN'), ('is', 'VBZ'), ('nearly', 'RB'), ('worn', 'VBN'), ('out', 'RP'), ('.', '.')]\n",
      "[('If', 'IN'), ('I', 'PRP'), ('had', 'VBD'), ('only', 'RB'), ('two', 'CD'), ('choices', 'NNS'), ('for', 'IN'), ('resources', 'NNS'), ('for', 'IN'), ('pastors', 'NNS'), ('of', 'IN'), ('small', 'JJ'), ('churches', 'NNS'), (',', ','), ('it', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('these', 'DT'), ('two.I', 'NNS'), ('hope', 'VBP'), ('the', 'DT'), ('author', 'NN'), ('considers', 'NNS'), ('focusing', 'VBG'), ('on', 'IN'), ('Christian', 'JJ'), ('Education', 'NN'), ('in', 'IN'), ('another', 'DT'), ('book', 'NN'), ('.', '.')]\n",
      "[('There', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('section', 'NN'), ('in', 'IN'), ('the', 'DT'), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('Big', 'NNP'), ('Small', 'NNP'), ('Church', 'NNP'), ('Book', 'NNP'), ('&', 'CC'), ('quot', 'NN'), (';', ':'), ('on', 'IN'), ('Christian', 'NNP'), ('Education', 'NNP'), (',', ','), ('but', 'CC'), ('concentrating', 'VBG'), ('on', 'IN'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('important', 'JJ'), ('church', 'NN'), ('functions', 'NNS'), ('individually', 'RB'), ('makes', 'VBZ'), ('a', 'DT'), ('huge', 'JJ'), ('difference', 'NN'), (',', ','), ('as', 'IN'), ('is', 'VBZ'), ('proven', 'VBN'), ('by', 'IN'), ('this', 'DT'), ('new', 'JJ'), ('book', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('tell', 'VBP'), ('all', 'DT'), ('my', 'PRP$'), ('colleagues', 'NNS'), ('that', 'IN'), ('Rev', 'NNP'), ('.', '.')]\n",
      "[('Ray', 'NNP'), (\"'s\", 'POS'), ('books', 'NNS'), ('are', 'VBP'), ('worth', 'JJ'), ('every', 'DT'), ('dollar', 'NN'), ('and', 'CC'), ('more', 'JJR'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos = [nltk.pos_tag(token) for token in tokens]\n",
    "for item in pos:\n",
    "    print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization (字型還原)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "just\n",
      "finish\n",
      "the\n",
      "book\n",
      ",\n",
      "&\n",
      "quot\n",
      ";\n",
      "Wonderful\n",
      "Worship\n",
      "in\n",
      "Smaller\n",
      "Churches\n",
      ",\n",
      "&\n",
      "quot\n",
      ";\n",
      "by\n",
      "David\n",
      "Ray\n",
      ",\n",
      "an\n",
      "outstanding\n",
      "resource\n",
      "for\n",
      "small\n",
      "church\n",
      "pastor\n",
      ",\n",
      "a\n",
      "be\n",
      "his\n",
      "other\n",
      "book\n",
      ",\n",
      "&\n",
      "quot\n",
      ";\n",
      "The\n",
      "Big\n",
      "Small\n",
      "Church\n",
      "Book.\n",
      "&\n",
      "quot\n",
      ";\n",
      "I\n",
      "will\n",
      "be\n",
      "reread\n",
      "both\n",
      "regularly\n",
      "and\n",
      "refer\n",
      "to\n",
      "them\n",
      "often\n",
      ".\n",
      "I\n",
      "may\n",
      "have\n",
      "to\n",
      "reorder\n",
      "the\n",
      "&\n",
      "quot\n",
      ";\n",
      "Big\n",
      "Small\n",
      "Church\n",
      "Book\n",
      "&\n",
      "quot\n",
      ";\n",
      "a\n",
      "my\n",
      "copy\n",
      "is\n",
      "nearly\n",
      "worn\n",
      "out\n",
      ".\n",
      "If\n",
      "I\n",
      "have\n",
      "only\n",
      "two\n",
      "choice\n",
      "for\n",
      "resource\n",
      "for\n",
      "pastor\n",
      "of\n",
      "small\n",
      "church\n",
      ",\n",
      "it\n",
      "would\n",
      "be\n",
      "these\n",
      "two.I\n",
      "hope\n",
      "the\n",
      "author\n",
      "considers\n",
      "focusing\n",
      "on\n",
      "Christian\n",
      "Education\n",
      "in\n",
      "another\n",
      "book\n",
      ".\n",
      "There\n",
      "is\n",
      "a\n",
      "section\n",
      "in\n",
      "the\n",
      "&\n",
      "quot\n",
      ";\n",
      "Big\n",
      "Small\n",
      "Church\n",
      "Book\n",
      "&\n",
      "quot\n",
      ";\n",
      "on\n",
      "Christian\n",
      "Education\n",
      ",\n",
      "but\n",
      "concentrating\n",
      "on\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "important\n",
      "church\n",
      "function\n",
      "individually\n",
      "make\n",
      "a\n",
      "huge\n",
      "difference\n",
      ",\n",
      "a\n",
      "is\n",
      "proven\n",
      "by\n",
      "this\n",
      "new\n",
      "book\n",
      ".\n",
      "I\n",
      "tell\n",
      "all\n",
      "my\n",
      "colleague\n",
      "that\n",
      "Rev\n",
      ".\n",
      "Ray\n",
      "'s\n",
      "book\n",
      "are\n",
      "worth\n",
      "every\n",
      "dollar\n",
      "and\n",
      "more\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "wordnet_pos = []\n",
    "for p in pos:\n",
    "    for word, tag in p:\n",
    "        if tag.startswith('J'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.ADJ)\n",
    "        elif tag.startswith('V'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.VERB)\n",
    "        elif tag.startswith('N'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n",
    "        elif tag.startswith('R'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.ADV)\n",
    "        else:\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "# Lemmatizer\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(p[n][0], pos=wordnet_pos[n]) for p in pos for n in range(len(p))]\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopword (停用詞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "finish\n",
      "book\n",
      ",\n",
      "&\n",
      "quot\n",
      ";\n",
      "Wonderful\n",
      "Worship\n",
      "Smaller\n",
      "Churches\n",
      ",\n",
      "&\n",
      "quot\n",
      ";\n",
      "David\n",
      "Ray\n",
      ",\n",
      "outstanding\n",
      "resource\n",
      "small\n",
      "church\n",
      "pastor\n",
      ",\n",
      "book\n",
      ",\n",
      "&\n",
      "quot\n",
      ";\n",
      "The\n",
      "Big\n",
      "Small\n",
      "Church\n",
      "Book.\n",
      "&\n",
      "quot\n",
      ";\n",
      "I\n",
      "reread\n",
      "regularly\n",
      "refer\n",
      "often\n",
      ".\n",
      "I\n",
      "may\n",
      "reorder\n",
      "&\n",
      "quot\n",
      ";\n",
      "Big\n",
      "Small\n",
      "Church\n",
      "Book\n",
      "&\n",
      "quot\n",
      ";\n",
      "copy\n",
      "nearly\n",
      "worn\n",
      ".\n",
      "If\n",
      "I\n",
      "two\n",
      "choice\n",
      "resource\n",
      "pastor\n",
      "small\n",
      "church\n",
      ",\n",
      "would\n",
      "two.I\n",
      "hope\n",
      "author\n",
      "considers\n",
      "focusing\n",
      "Christian\n",
      "Education\n",
      "another\n",
      "book\n",
      ".\n",
      "There\n",
      "section\n",
      "&\n",
      "quot\n",
      ";\n",
      "Big\n",
      "Small\n",
      "Church\n",
      "Book\n",
      "&\n",
      "quot\n",
      ";\n",
      "Christian\n",
      "Education\n",
      ",\n",
      "concentrating\n",
      "one\n",
      "important\n",
      "church\n",
      "function\n",
      "individually\n",
      "make\n",
      "huge\n",
      "difference\n",
      ",\n",
      "proven\n",
      "new\n",
      "book\n",
      ".\n",
      "I\n",
      "tell\n",
      "colleague\n",
      "Rev\n",
      ".\n",
      "Ray\n",
      "'s\n",
      "book\n",
      "worth\n",
      "every\n",
      "dollar\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "tokens = [token for token in tokens if token not in nltk_stopwords]\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER (命名實體辨識)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Christian', 'GPE')\n",
      "('Ray', 'PERSON')\n",
      "('Smaller Churches', 'PERSON')\n",
      "('David Ray', 'PERSON')\n",
      "('Rev', 'PERSON')\n",
      "('Church Book', 'PERSON')\n",
      "('Christian Education', 'PERSON')\n",
      "('Wonderful Worship', 'PERSON')\n",
      "('Church', 'PERSON')\n"
     ]
    }
   ],
   "source": [
    "ne_chunked_sents = [nltk.ne_chunk(tag) for tag in pos]\n",
    "named_entities = []\n",
    "\n",
    "for ne_tagged_sentence in ne_chunked_sents:\n",
    "    for tagged_tree in ne_tagged_sentence:\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tagged_tree.leaves())\n",
    "            entity_type = tagged_tree.label()\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "            named_entities = list(set(named_entities))\n",
    "\n",
    "for ner in named_entities:\n",
    "    print(ner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pandas.read_csv(f\"{path}\\Books_data.csv\")\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_data.columns:\n",
    "    print(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
